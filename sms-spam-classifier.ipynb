{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/chethuhn/sms-spam-classifier?scriptVersionId=134283875\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-20T16:25:36.757903Z","iopub.execute_input":"2023-06-20T16:25:36.758317Z","iopub.status.idle":"2023-06-20T16:25:36.77371Z","shell.execute_reply.started":"2023-06-20T16:25:36.758282Z","shell.execute_reply":"2023-06-20T16:25:36.772649Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/sms-spam-collection-dataset/spam.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:36.775968Z","iopub.execute_input":"2023-06-20T16:25:36.776598Z","iopub.status.idle":"2023-06-20T16:25:36.993802Z","shell.execute_reply.started":"2023-06-20T16:25:36.776567Z","shell.execute_reply":"2023-06-20T16:25:36.992911Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/sms-spam-collection-dataset/spam.csv\",sep=\",\",encoding=\"ISO-8859-1\")\ndf","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:36.995298Z","iopub.execute_input":"2023-06-20T16:25:36.995638Z","iopub.status.idle":"2023-06-20T16:25:37.047182Z","shell.execute_reply.started":"2023-06-20T16:25:36.995609Z","shell.execute_reply":"2023-06-20T16:25:37.046302Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        v1                                                 v2 Unnamed: 2  \\\n0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n1      ham                      Ok lar... Joking wif u oni...        NaN   \n2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n3      ham  U dun say so early hor... U c already then say...        NaN   \n4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n...    ...                                                ...        ...   \n5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n5571   ham                         Rofl. Its true to its name        NaN   \n\n     Unnamed: 3 Unnamed: 4  \n0           NaN        NaN  \n1           NaN        NaN  \n2           NaN        NaN  \n3           NaN        NaN  \n4           NaN        NaN  \n...         ...        ...  \n5567        NaN        NaN  \n5568        NaN        NaN  \n5569        NaN        NaN  \n5570        NaN        NaN  \n5571        NaN        NaN  \n\n[5572 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>Unnamed: 2</th>\n      <th>Unnamed: 3</th>\n      <th>Unnamed: 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5567</th>\n      <td>spam</td>\n      <td>This is the 2nd time we have tried 2 contact u...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5568</th>\n      <td>ham</td>\n      <td>Will Ì_ b going to esplanade fr home?</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5569</th>\n      <td>ham</td>\n      <td>Pity, * was in mood for that. So...any other s...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5570</th>\n      <td>ham</td>\n      <td>The guy did some bitching but I acted like i'd...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5571</th>\n      <td>ham</td>\n      <td>Rofl. Its true to its name</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5572 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:37.04989Z","iopub.execute_input":"2023-06-20T16:25:37.050566Z","iopub.status.idle":"2023-06-20T16:25:37.057275Z","shell.execute_reply.started":"2023-06-20T16:25:37.050533Z","shell.execute_reply":"2023-06-20T16:25:37.056175Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:37.05873Z","iopub.execute_input":"2023-06-20T16:25:37.059483Z","iopub.status.idle":"2023-06-20T16:25:37.069308Z","shell.execute_reply.started":"2023-06-20T16:25:37.059452Z","shell.execute_reply":"2023-06-20T16:25:37.068351Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df.rename({\"v1\":\"label\",\"v2\":\"message\"},axis=1,inplace=True)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:37.071537Z","iopub.execute_input":"2023-06-20T16:25:37.071844Z","iopub.status.idle":"2023-06-20T16:25:37.088036Z","shell.execute_reply.started":"2023-06-20T16:25:37.07182Z","shell.execute_reply":"2023-06-20T16:25:37.086975Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"     label                                            message\n0      ham  Go until jurong point, crazy.. Available only ...\n1      ham                      Ok lar... Joking wif u oni...\n2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3      ham  U dun say so early hor... U c already then say...\n4      ham  Nah I don't think he goes to usf, he lives aro...\n...    ...                                                ...\n5567  spam  This is the 2nd time we have tried 2 contact u...\n5568   ham              Will Ì_ b going to esplanade fr home?\n5569   ham  Pity, * was in mood for that. So...any other s...\n5570   ham  The guy did some bitching but I acted like i'd...\n5571   ham                         Rofl. Its true to its name\n\n[5572 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5567</th>\n      <td>spam</td>\n      <td>This is the 2nd time we have tried 2 contact u...</td>\n    </tr>\n    <tr>\n      <th>5568</th>\n      <td>ham</td>\n      <td>Will Ì_ b going to esplanade fr home?</td>\n    </tr>\n    <tr>\n      <th>5569</th>\n      <td>ham</td>\n      <td>Pity, * was in mood for that. So...any other s...</td>\n    </tr>\n    <tr>\n      <th>5570</th>\n      <td>ham</td>\n      <td>The guy did some bitching but I acted like i'd...</td>\n    </tr>\n    <tr>\n      <th>5571</th>\n      <td>ham</td>\n      <td>Rofl. Its true to its name</td>\n    </tr>\n  </tbody>\n</table>\n<p>5572 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## To check the the dataset is Balanced or Imbalaced \ndf[\"label\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:37.089344Z","iopub.execute_input":"2023-06-20T16:25:37.089851Z","iopub.status.idle":"2023-06-20T16:25:37.105238Z","shell.execute_reply.started":"2023-06-20T16:25:37.089819Z","shell.execute_reply":"2023-06-20T16:25:37.103896Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"ham     4825\nspam     747\nName: label, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"sns.countplot(x=df[\"label\"],)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:37.106899Z","iopub.execute_input":"2023-06-20T16:25:37.107856Z","iopub.status.idle":"2023-06-20T16:25:37.334684Z","shell.execute_reply.started":"2023-06-20T16:25:37.107826Z","shell.execute_reply":"2023-06-20T16:25:37.33387Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<Axes: xlabel='label', ylabel='count'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"from the above plot we can see that dataset is imbalanced","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import *\n\nimport re","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:37.335814Z","iopub.execute_input":"2023-06-20T16:25:37.336766Z","iopub.status.idle":"2023-06-20T16:25:37.945007Z","shell.execute_reply.started":"2023-06-20T16:25:37.336735Z","shell.execute_reply":"2023-06-20T16:25:37.94405Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"corpus=[]\nstemmer=PorterStemmer()","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:37.948873Z","iopub.execute_input":"2023-06-20T16:25:37.949167Z","iopub.status.idle":"2023-06-20T16:25:37.954057Z","shell.execute_reply.started":"2023-06-20T16:25:37.949144Z","shell.execute_reply":"2023-06-20T16:25:37.953179Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"corpus=[]\nfor i in range(len(df['message'])):\n    review=re.sub('[^a-zA-Z]',' ',df['message'][i]) ## First remove the non word characters\n    review=review.lower()\n    review=review.split()\n    review=[stemmer.stem(word) for word in review if not word in stopwords.words(\"english\")]\n    review=\" \".join(review)\n    corpus.append(review)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:37.955609Z","iopub.execute_input":"2023-06-20T16:25:37.9563Z","iopub.status.idle":"2023-06-20T16:25:49.709371Z","shell.execute_reply.started":"2023-06-20T16:25:37.956248Z","shell.execute_reply":"2023-06-20T16:25:49.70838Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"corpus[5]","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:49.710755Z","iopub.execute_input":"2023-06-20T16:25:49.711151Z","iopub.status.idle":"2023-06-20T16:25:49.717958Z","shell.execute_reply.started":"2023-06-20T16:25:49.711116Z","shell.execute_reply":"2023-06-20T16:25:49.717098Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'freemsg hey darl week word back like fun still tb ok xxx std chg send rcv'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Bag of Words Model for Text representation of independenet feature","metadata":{}},{"cell_type":"code","source":"import sklearn\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer(max_features=5000) \n## we are just trying top 5000 Words,then we can tune it accoring to accuracy and other matrix\nX = vectorizer.fit_transform(corpus).toarray()","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:49.719534Z","iopub.execute_input":"2023-06-20T16:25:49.720251Z","iopub.status.idle":"2023-06-20T16:25:49.897651Z","shell.execute_reply.started":"2023-06-20T16:25:49.720221Z","shell.execute_reply":"2023-06-20T16:25:49.896611Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"## This is Sparsed Matrix of Dependent features \nX,X.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:49.899584Z","iopub.execute_input":"2023-06-20T16:25:49.900033Z","iopub.status.idle":"2023-06-20T16:25:49.908948Z","shell.execute_reply.started":"2023-06-20T16:25:49.899973Z","shell.execute_reply":"2023-06-20T16:25:49.908007Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(array([[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]),\n (5572, 5000))"},"metadata":{}}]},{"cell_type":"code","source":"df[\"label\"].unique()","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:49.910313Z","iopub.execute_input":"2023-06-20T16:25:49.911307Z","iopub.status.idle":"2023-06-20T16:25:49.919823Z","shell.execute_reply.started":"2023-06-20T16:25:49.911274Z","shell.execute_reply":"2023-06-20T16:25:49.918855Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"array(['ham', 'spam'], dtype=object)"},"metadata":{}}]},{"cell_type":"markdown","source":"#### We treansformed the dependent features but our Indpendent(Target) feature is yet to be converted into numerical.\n - Because this column has only 2 Categories we can try one-Hot Encoding or pd.get_dummies\n","metadata":{}},{"cell_type":"code","source":"y=pd.get_dummies(df[\"label\"])","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:49.92146Z","iopub.execute_input":"2023-06-20T16:25:49.921945Z","iopub.status.idle":"2023-06-20T16:25:49.930146Z","shell.execute_reply.started":"2023-06-20T16:25:49.921911Z","shell.execute_reply":"2023-06-20T16:25:49.929003Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:49.931726Z","iopub.execute_input":"2023-06-20T16:25:49.932102Z","iopub.status.idle":"2023-06-20T16:25:49.944668Z","shell.execute_reply.started":"2023-06-20T16:25:49.932071Z","shell.execute_reply":"2023-06-20T16:25:49.943644Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"      ham  spam\n0       1     0\n1       1     0\n2       0     1\n3       1     0\n4       1     0\n...   ...   ...\n5567    0     1\n5568    1     0\n5569    1     0\n5570    1     0\n5571    1     0\n\n[5572 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ham</th>\n      <th>spam</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5567</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5568</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5569</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5570</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5571</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5572 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We can drop one column because we can predict both results in one column only and we can do that in pd.get_dummies function","metadata":{}},{"cell_type":"code","source":"## Now we are getting the Spam Column into the model\ny=pd.get_dummies(df[\"label\"],drop_first=True)\ny","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:49.946253Z","iopub.execute_input":"2023-06-20T16:25:49.946591Z","iopub.status.idle":"2023-06-20T16:25:49.959566Z","shell.execute_reply.started":"2023-06-20T16:25:49.946561Z","shell.execute_reply":"2023-06-20T16:25:49.958592Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"      spam\n0        0\n1        0\n2        1\n3        0\n4        0\n...    ...\n5567     1\n5568     0\n5569     0\n5570     0\n5571     0\n\n[5572 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spam</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5567</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5568</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5569</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5570</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5571</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5572 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Gaussian Naive Bayes\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\ngnb = GaussianNB()\ny_pred = gnb.fit(X_train, y_train).predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:49.960923Z","iopub.execute_input":"2023-06-20T16:25:49.961499Z","iopub.status.idle":"2023-06-20T16:25:50.516359Z","shell.execute_reply.started":"2023-06-20T16:25:49.96147Z","shell.execute_reply":"2023-06-20T16:25:50.515307Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"## To get unique values in test data and total size of test data\ny_test.value_counts(),len(y_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:50.518185Z","iopub.execute_input":"2023-06-20T16:25:50.518591Z","iopub.status.idle":"2023-06-20T16:25:50.530403Z","shell.execute_reply.started":"2023-06-20T16:25:50.518553Z","shell.execute_reply":"2023-06-20T16:25:50.529348Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(spam\n 0       1453\n 1        219\n dtype: int64,\n 1672)"},"metadata":{}}]},{"cell_type":"markdown","source":"##### In the Test data we have  0 Means Ham and 1 Means Spam and we have 219 Instance of Spam Entries and 1453 instance of Ham Entries ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import *\n\nacc=accuracy_score(y_test, y_pred)\ncm=confusion_matrix(y_test, y_pred)\na=precision_recall_fscore_support(y_test, y_pred, average='binary')\n\nprint(f'Gaussian Naive Bayes Model is Giving These metrics after Text \"Representation by BOW Model\", \\n\\n Accuracy of this model is {acc} ,\\n\\n Confusion Matrix for this model \\n\\n{cm}, \\n\\n Precision,Recall,F-1 score for Binary Average of data are \\n\\n{a} \\n\\n')\ntarget_names = ['ham', 'spam']\nreport = classification_report(y_test, y_pred, target_names=target_names,labels=None)\n\nprint(f\"Classification report for this model \\n\\n{report}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:25:50.532181Z","iopub.execute_input":"2023-06-20T16:25:50.532517Z","iopub.status.idle":"2023-06-20T16:25:50.568008Z","shell.execute_reply.started":"2023-06-20T16:25:50.532487Z","shell.execute_reply":"2023-06-20T16:25:50.566934Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Gaussian Naive Bayes Model is Giving These metrics after Text \"Representation by BOW Model\", \n\n Accuracy of this model is 0.8654306220095693 ,\n\n Confusion Matrix for this model \n\n[[1255  198]\n [  27  192]], \n\n Precision,Recall,F-1 score for Binary Average of data are \n\n(0.49230769230769234, 0.8767123287671232, 0.6305418719211823, None) \n\n\nClassification report for this model \n\n              precision    recall  f1-score   support\n\n         ham       0.98      0.86      0.92      1453\n        spam       0.49      0.88      0.63       219\n\n    accuracy                           0.87      1672\n   macro avg       0.74      0.87      0.77      1672\nweighted avg       0.92      0.87      0.88      1672\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"1. Precision: It measures the proportion of correctly predicted instances out of the total predicted instances for each class.\n\n2. Recall: It measures the proportion of correctly predicted instances out of the total actual instances for each class.\n\n3. F1-score: It is the harmonic mean of precision and recall and provides a balanced measure of a classifier's performance.\n\n4. Support: It represents the number of instances in each class.\n\n5. Accuracy: It indicates the overall accuracy of the classifier.\n### 'binary' average:\nIf your focus is solely on evaluating the performance of identifying spam instances, you can use the 'binary' average. This average calculates the F1 score specifically for the positive class (spam) while treating the negative class as non-spam. It is suitable if your primary concern is the accuracy of spam detection.\n\n### 'macro' or 'weighted' average: \nIf you want to evaluate the model's performance across both spam and non-spam classes, you can use the 'macro' or 'weighted' average. The 'macro' average treats both classes equally, while the 'weighted' average takes into account class imbalance and varying sample sizes. These averages provide an overall assessment of the model's performance, considering both precision and recall for both classes.\n\n### Reason for Changes in Precision and recall for each average \n\nWhen you change the average parameter in the F1 score calculation, it can affect the precision and recall values, which in turn impacts the resulting F1 score. Here's why the precision and recall may change when you switch between different averaging options:\n\n### 1. 'binary' average:\n\nPrecision and recall are calculated specifically for the positive class (as specified by pos_label), treating the negative class as non-positive\n.\nPrecision: The proportion of true positive predictions out of all positive predictions. Only predictions related to the positive class are considered.\n\nRecall: The proportion of true positive predictions out of all actual positive instances. Only instances related to the positive class are considered.\n\n### 2. 'macro' average:\n\nPrecision and recall are calculated independently for each class and then averaged.\n\nPrecision: The average of precision values calculated for each class.\n\nRecall: The average of recall values calculated for each class.\n### 3. 'weighted' average:\n\nPrecision and recall are calculated independently for each class and then weighted by the number of samples in each class before averaging.\n\nPrecision: The weighted average of precision values, considering the class imbalance.\n\nRecall: The weighted average of recall values, considering the class imbalance.\nWhen you switch between these averaging options, the way precision and recall are computed changes, leading to potential variations in their values. \n\nThe choice of averaging option can affect how much weight is given to each class and how the contributions of different classes are combined to calculate the final precision and recall values.\n\nIt's worth noting that depending on the class distribution and the performance of your model, different averaging options may result in different F1 scores. It's important to interpret and consider the implications of each average in the context of your specific problem and the evaluation requirements you have.","metadata":{}},{"cell_type":"markdown","source":"#### We are getting the 86% , if we provide \"spam\" column as the \"Target(y)\" Column, we can change the column for \"ham\" and will check for accuracy, because , the ham frequency is greater than spam","metadata":{}},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:27:51.520629Z","iopub.execute_input":"2023-06-20T16:27:51.521067Z","iopub.status.idle":"2023-06-20T16:27:51.533476Z","shell.execute_reply.started":"2023-06-20T16:27:51.521037Z","shell.execute_reply":"2023-06-20T16:27:51.532535Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"     label                                            message\n0      ham  Go until jurong point, crazy.. Available only ...\n1      ham                      Ok lar... Joking wif u oni...\n2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3      ham  U dun say so early hor... U c already then say...\n4      ham  Nah I don't think he goes to usf, he lives aro...\n...    ...                                                ...\n5567  spam  This is the 2nd time we have tried 2 contact u...\n5568   ham              Will Ì_ b going to esplanade fr home?\n5569   ham  Pity, * was in mood for that. So...any other s...\n5570   ham  The guy did some bitching but I acted like i'd...\n5571   ham                         Rofl. Its true to its name\n\n[5572 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5567</th>\n      <td>spam</td>\n      <td>This is the 2nd time we have tried 2 contact u...</td>\n    </tr>\n    <tr>\n      <th>5568</th>\n      <td>ham</td>\n      <td>Will Ì_ b going to esplanade fr home?</td>\n    </tr>\n    <tr>\n      <th>5569</th>\n      <td>ham</td>\n      <td>Pity, * was in mood for that. So...any other s...</td>\n    </tr>\n    <tr>\n      <th>5570</th>\n      <td>ham</td>\n      <td>The guy did some bitching but I acted like i'd...</td>\n    </tr>\n    <tr>\n      <th>5571</th>\n      <td>ham</td>\n      <td>Rofl. Its true to its name</td>\n    </tr>\n  </tbody>\n</table>\n<p>5572 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## Now we are getting the Spam Column into the model\ny=pd.get_dummies(df[\"label\"],drop_first=True)\ny","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:29:10.641733Z","iopub.execute_input":"2023-06-20T16:29:10.642117Z","iopub.status.idle":"2023-06-20T16:29:10.656068Z","shell.execute_reply.started":"2023-06-20T16:29:10.642089Z","shell.execute_reply":"2023-06-20T16:29:10.655062Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"      spam\n0        0\n1        0\n2        1\n3        0\n4        0\n...    ...\n5567     1\n5568     0\n5569     0\n5570     0\n5571     0\n\n[5572 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spam</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5567</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5568</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5569</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5570</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5571</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5572 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## To check the accuracy of model changes if we provide 1 for spam\ny.replace([0,1],[1,0],inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:30:01.694426Z","iopub.execute_input":"2023-06-20T16:30:01.694848Z","iopub.status.idle":"2023-06-20T16:30:01.701232Z","shell.execute_reply.started":"2023-06-20T16:30:01.694812Z","shell.execute_reply":"2023-06-20T16:30:01.700253Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\ngnb = GaussianNB()\ny_pred = gnb.fit(X_train, y_train).predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:30:03.114612Z","iopub.execute_input":"2023-06-20T16:30:03.11509Z","iopub.status.idle":"2023-06-20T16:30:03.743185Z","shell.execute_reply.started":"2023-06-20T16:30:03.115048Z","shell.execute_reply":"2023-06-20T16:30:03.741945Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"y_test.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:30:07.516393Z","iopub.execute_input":"2023-06-20T16:30:07.516745Z","iopub.status.idle":"2023-06-20T16:30:07.52644Z","shell.execute_reply.started":"2023-06-20T16:30:07.516716Z","shell.execute_reply":"2023-06-20T16:30:07.525381Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"spam\n1       1453\n0        219\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"##### In the Test data we have  0 Means Spam and 1 Means Ham and we have 219 Instance of Spam Entries and 1453 instance of Ham Entries ","metadata":{}},{"cell_type":"code","source":"acc=accuracy_score(y_test, y_pred)\ncm=confusion_matrix(y_test, y_pred)\na=precision_recall_fscore_support(y_test, y_pred, average='binary')\n\nprint(f'Gaussian Naive Bayes Model is Giving These metrics after Text \"Representation by BOW Model\", \\n\\n Accuracy of this model is {acc} ,\\n\\n Confusion Matrix for this model \\n\\n{cm}, \\n\\n Precision,Recall,F-1 score for Binary Average of data are \\n\\n{a} \\n\\n')\ntarget_names = ['Spam', 'Ham']\nreport = classification_report(y_test, y_pred, target_names=target_names,labels=None)\n\nprint(f\"Classification report for this model \\n\\n{report}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:36:33.941846Z","iopub.execute_input":"2023-06-20T16:36:33.942543Z","iopub.status.idle":"2023-06-20T16:36:33.975741Z","shell.execute_reply.started":"2023-06-20T16:36:33.942509Z","shell.execute_reply":"2023-06-20T16:36:33.974764Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Gaussian Naive Bayes Model is Giving These metrics after Text \"Representation by BOW Model\", \n\n Accuracy of this model is 0.8809808612440191 ,\n\n Confusion Matrix for this model \n\n[[1264  162]\n [  37  209]], \n\n Precision,Recall,F-1 score for Binary Average of data are \n\n(0.5633423180592992, 0.8495934959349594, 0.6774716369529984, None) \n\n\nClassification report for this model \n\n              precision    recall  f1-score   support\n\n        Spam       0.97      0.89      0.93      1426\n         Ham       0.56      0.85      0.68       246\n\n    accuracy                           0.88      1672\n   macro avg       0.77      0.87      0.80      1672\nweighted avg       0.91      0.88      0.89      1672\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### We are able to increase the accuracy from 86% to 88% ,\n## Let's see what else we can tune the parameters so that we can increase the accuracy of the model\n- stemming into lemmatisation  \n- max_features(Top Features) in the model\n- changing BOW model into TF-IDF Model","metadata":{}},{"cell_type":"code","source":"## Now we are getting the Spam Column into the model\ny=pd.get_dummies(df[\"label\"],drop_first=True)\ny","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:46:18.925304Z","iopub.execute_input":"2023-06-20T16:46:18.925895Z","iopub.status.idle":"2023-06-20T16:46:18.940876Z","shell.execute_reply.started":"2023-06-20T16:46:18.925863Z","shell.execute_reply":"2023-06-20T16:46:18.939516Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"      spam\n0        0\n1        0\n2        1\n3        0\n4        0\n...    ...\n5567     1\n5568     0\n5569     0\n5570     0\n5571     0\n\n[5572 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spam</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5567</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5568</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5569</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5570</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5571</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5572 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## To check the accuracy of model changes if we provide 1 for spam\ny.replace([0,1],[1,0],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:46:23.608366Z","iopub.execute_input":"2023-06-20T16:46:23.608727Z","iopub.status.idle":"2023-06-20T16:46:23.613973Z","shell.execute_reply.started":"2023-06-20T16:46:23.608698Z","shell.execute_reply":"2023-06-20T16:46:23.613114Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"## We are checking for TF-IDF model","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import *\nvectorizer =TfidfVectorizer(max_features=3000) \n## we are just trying top 5000 Words,then we can tune it accoring to accuracy and other matrix\nX = vectorizer.fit_transform(corpus).toarray()","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:46:28.453432Z","iopub.execute_input":"2023-06-20T16:46:28.456552Z","iopub.status.idle":"2023-06-20T16:46:28.740855Z","shell.execute_reply.started":"2023-06-20T16:46:28.456515Z","shell.execute_reply":"2023-06-20T16:46:28.739737Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"## Sparse Matrix after TF-IDF Converting\nX","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:46:32.025785Z","iopub.execute_input":"2023-06-20T16:46:32.026149Z","iopub.status.idle":"2023-06-20T16:46:32.033906Z","shell.execute_reply.started":"2023-06-20T16:46:32.026119Z","shell.execute_reply":"2023-06-20T16:46:32.032941Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)\ngnb = GaussianNB()\ny_pred = gnb.fit(X_train, y_train).predict(X_test)\n\nacc=accuracy_score(y_test, y_pred)\ncm=confusion_matrix(y_test, y_pred)\na=precision_recall_fscore_support(y_test, y_pred, average='binary')\n\nprint(f'Gaussian Naive Bayes Model is Giving These metrics after \"Text Representation by TF-IDF Model\", \\n\\n Accuracy of this model is {acc} ,\\n\\n Confusion Matrix for this model \\n\\n{cm}, \\n\\n Precision,Recall,F-1 score for Binary Average of data are \\n\\n{a} \\n\\n')\ntarget_names = ['Spam', 'Ham']\nreport = classification_report(y_test, y_pred, target_names=target_names,labels=None)\n\nprint(f\"Classification report for this model \\n\\n{report}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:48:35.350431Z","iopub.execute_input":"2023-06-20T16:48:35.350793Z","iopub.status.idle":"2023-06-20T16:48:35.646689Z","shell.execute_reply.started":"2023-06-20T16:48:35.350766Z","shell.execute_reply":"2023-06-20T16:48:35.645432Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"},{"name":"stdout","text":"Gaussian Naive Bayes Model is Giving These metrics after \"Text Representation by TF-IDF Model\", \n\n Accuracy of this model is 0.8809808612440191 ,\n\n Confusion Matrix for this model \n\n[[ 209   37]\n [ 162 1264]], \n\n Precision,Recall,F-1 score for Binary Average of data are \n\n(0.9715603382013835, 0.8863955119214586, 0.927026035936927, None) \n\n\nClassification report for this model \n\n              precision    recall  f1-score   support\n\n        Spam       0.56      0.85      0.68       246\n         Ham       0.97      0.89      0.93      1426\n\n    accuracy                           0.88      1672\n   macro avg       0.77      0.87      0.80      1672\nweighted avg       0.91      0.88      0.89      1672\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### By changing the  Text Representation(Encoding) of features from BOW  Model to TF-IDF Model ,we are getting the same results as BOW Model Text Representaion\n\n- Lets change the Classification model and check","metadata":{}},{"cell_type":"markdown","source":"## Multinomial Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import *\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)\nmnb = MultinomialNB ()\ny_pred = mnb.fit(X_train, y_train).predict(X_test)\n\n## Metrics to Check the Model Performance\nacc=accuracy_score(y_test, y_pred)\ncm=confusion_matrix(y_test, y_pred)\na=precision_recall_fscore_support(y_test, y_pred, average='binary')\n\nprint(f'Gaussian Naive Bayes Model is Giving These metrics after \"Text Representation by TF-IDF Model\", \\n\\n Accuracy of this model is {acc} ,\\n\\n Confusion Matrix for this model \\n\\n{cm}, \\n\\n Precision,Recall,F-1 score for Binary Average of data are \\n\\n{a} \\n\\n')\ntarget_names = ['Spam', 'Ham']\nreport = classification_report(y_test, y_pred, target_names=target_names,labels=None)\n\nprint(f\"Classification report for this model \\n\\n {report}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:50:19.697847Z","iopub.execute_input":"2023-06-20T16:50:19.698509Z","iopub.status.idle":"2023-06-20T16:50:19.846481Z","shell.execute_reply.started":"2023-06-20T16:50:19.698475Z","shell.execute_reply":"2023-06-20T16:50:19.845502Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Gaussian Naive Bayes Model is Giving These metrics after \"Text Representation by TF-IDF Model\", \n\n Accuracy of this model is 0.9683014354066986 ,\n\n Confusion Matrix for this model \n\n[[ 194   52]\n [   1 1425]], \n\n Precision,Recall,F-1 score for Binary Average of data are \n\n(0.9647935003385241, 0.9992987377279102, 0.9817430244574578, None) \n\n\nClassification report for this model \n\n              precision    recall  f1-score   support\n\n        Spam       0.99      0.79      0.88       246\n         Ham       0.96      1.00      0.98      1426\n\n    accuracy                           0.97      1672\n   macro avg       0.98      0.89      0.93      1672\nweighted avg       0.97      0.97      0.97      1672\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### We are getting better results in Multinomial Naive Bayes Model, lets check for other algorithms also","metadata":{}},{"cell_type":"markdown","source":"### Complement Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import *\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)\ncnb = ComplementNB()\ny_pred = cnb.fit(X_train, y_train).predict(X_test)\naccuracy_score(y_test, y_pred),confusion_matrix(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We are getting accuracy of 92% which is below multinominal naive bayes model","metadata":{}},{"cell_type":"markdown","source":"###  Bernoulli Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import *\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)\nbnb = BernoulliNB()\ny_pred = bnb.fit(X_train, y_train).predict(X_test)\naccuracy_score(y_test, y_pred),confusion_matrix(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### we are getting better results from  Bernoulli Naive Bayes Model which is giving 97.78%, so we are finalising this model \n\n### But  lets see we can increase accuracy and decrease False positives and False Negatives little bit by changing text representation part from stemming into lemmatization","metadata":{}},{"cell_type":"code","source":"nltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2023-06-20T17:49:17.971484Z","iopub.execute_input":"2023-06-20T17:49:17.97184Z","iopub.status.idle":"2023-06-20T17:49:18.098835Z","shell.execute_reply.started":"2023-06-20T17:49:17.971813Z","shell.execute_reply":"2023-06-20T17:49:18.097891Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"!pip install wordnet","metadata":{"execution":{"iopub.status.busy":"2023-06-20T17:49:21.129686Z","iopub.execute_input":"2023-06-20T17:49:21.130222Z","iopub.status.idle":"2023-06-20T17:49:36.271385Z","shell.execute_reply.started":"2023-06-20T17:49:21.130189Z","shell.execute_reply":"2023-06-20T17:49:36.269758Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"Collecting wordnet\n  Downloading wordnet-0.0.1b2.tar.gz (8.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting colorama==0.3.9 (from wordnet)\n  Downloading colorama-0.3.9-py2.py3-none-any.whl (20 kB)\nBuilding wheels for collected packages: wordnet\n  Building wheel for wordnet (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wordnet: filename=wordnet-0.0.1b2-py3-none-any.whl size=10520 sha256=9dbdf2fb547cbc3246136e5629f8309de01c113ede07cfad25ae38a3159e650a\n  Stored in directory: /root/.cache/pip/wheels/c0/a1/e8/4649c8712033dcdbd1e64a0fc75216a5d1769665852c36b4f9\nSuccessfully built wordnet\nInstalling collected packages: colorama, wordnet\n  Attempting uninstall: colorama\n    Found existing installation: colorama 0.4.6\n    Uninstalling colorama-0.4.6:\n      Successfully uninstalled colorama-0.4.6\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbayesian-optimization 1.4.3 requires colorama>=0.4.6, but you have colorama 0.3.9 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed colorama-0.3.9 wordnet-0.0.1b2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from nltk.corpus import wordnet\nnltk.corpus.wordnet\n#from wordnet import Dictionary\nnltk.download('wordnet')\n## To unzip the corpora wordnet\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2023-06-20T17:49:36.274407Z","iopub.execute_input":"2023-06-20T17:49:36.274792Z","iopub.status.idle":"2023-06-20T17:49:37.609393Z","shell.execute_reply.started":"2023-06-20T17:49:36.274749Z","shell.execute_reply":"2023-06-20T17:49:37.608302Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\ncorpus=[]\nwnl=WordNetLemmatizer()\n\nfor i in range(len(df)):\n    review=re.sub('[^a-zA-Z]',\" \",df[\"message\"][i])\n    review=review.lower().split()\n    review=[wnl.lemmatize(word) for word in review if not word in stopwords.words('english')]\n    review=\" \".join(review)\n    corpus.append(review)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T17:49:37.784447Z","iopub.execute_input":"2023-06-20T17:49:37.784791Z","iopub.status.idle":"2023-06-20T17:49:50.659491Z","shell.execute_reply.started":"2023-06-20T17:49:37.78475Z","shell.execute_reply":"2023-06-20T17:49:50.658506Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import *\nmodel=CountVectorizer(max_features=6000)\nX=model.fit_transform(corpus).toarray()\nX,X.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import *\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)\nbnb = BernoulliNB()\ny_pred = bnb.fit(X_train, y_train).predict(X_test)\naccuracy_score(y_test, y_pred),confusion_matrix(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Accuracy for this model is 97.78%","metadata":{}},{"cell_type":"markdown","source":"## Conclusion\n\n 1. for this dataset the Text representation Model TF-IDF is giving Better results than Bag of Words Model\n 2. The Bernoulli Naive Bayes  Model is giving Best results \n 3. Optimal Number of Top features in the text representation is 6000\n ","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n\ndef preprocess_text(text, use_stemming=True, use_lemmatization=True):\n    corpus=[]\n\n    # Code to preprocess the text based on the use_stemming parameter\n    # You can replace this with your own text preprocessing logic\n    if use_lemmatization:\n        lemmatizer = WordNetLemmatizer()\n        processed_text = [lemmatizer.lemmatize(word) for word in text.split()]\n    else:\n        processed_text = text.split()\n\n    if use_stemming:\n        stemmer = PorterStemmer()\n        stopwords_list = set(stopwords.words('english'))\n        processed_text = [stemmer.stem(word) for word in processed_text if word.lower() not in stopwords_list]\n\n    return ' '.join(processed_text)\nfor i in range(len(df['message'])):\n    ## First remove the non word characters\n    review=re.sub('[^a-zA-Z]',' ',df['message'][i]) \n    ## To lowcase all the words , so that model learns ,different cases of 1 Alphabet is same letter\n    review=review.lower() \n    review=review.split()\n    review=[stemmer.stem(word) for word in review if not word in stopwords.words(\"english\")]\n    review=\" \".join(review)\n    corpus.append(review)\n\ndef evaluate_model(model, data, use_stemming):\n    # Code to evaluate the model using the provided data and calculate performance metrics\n    preprocessed_text = [preprocess_text(text, use_stemming) for text in data['text']]\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(preprocessed_text)\n    y = data['labels']\n    predictions = model.predict(X)\n    accuracy = accuracy_score(y, predictions)\n    f1_micro = f1_score(y, predictions, average='micro')\n    f1_macro = f1_score(y, predictions, average='macro')\n    f1_weighted = f1_score(y, predictions, average='weighted')\n    recall_micro = recall_score(y, predictions, average='micro')\n    recall_macro = recall_score(y, predictions, average='macro')\n    recall_weighted = recall_score(y, predictions, average='weighted')\n    precision_micro = precision_score(y, predictions, average='micro')\n    precision_macro = precision_score(y, predictions, average='macro')\n    precision_weighted = precision_score(y, predictions, average='weighted')\n    cm = confusion_matrix(y, predictions)\n\n    return {\n        'accuracy': accuracy,\n        'f1_micro': f1_micro,\n        'f1_macro': f1_macro,\n        'f1_weighted': f1_weighted,\n        'recall_micro': recall_micro,\n        'recall_macro': recall_macro,\n        'recall_weighted': recall_weighted,\n        'precision_micro': precision_micro,\n        'precision_macro': precision_macro,\n        'precision_weighted': precision_weighted,\n        'confusion_matrix': cm\n    }\n\ndef find_best_model(models, data):\n    best_model = None\n    best_f1_score = float('-inf')\n\n    for model in models:\n        for use_stemming in [True, False]:\n            model_results = evaluate_model(model, data, use_stemming)\n            f1_avg = (model_results['f1_micro'] + model_results['f1_macro'] + model_results['f1_weighted']) / 3\n\n            # Print the results for each model and stemming variation\n            print(\"Model:\", model)\n            print(\"Use Stemming:\", use_stemming)\n            print(\"Accuracy:\", model_results['accuracy'])\n            print(\"F1 Score (Micro):\", model_results['f1_micro'])\n            print(\"F1 Score (Macro):\", model_results['f1_macro'])\n            print(\"F1 Score (Weighted):\", model_results['f1_weighted'])\n            print(\"Recall (Micro):\", model_results['recall_micro'])\n            print(\"Recall (Macro):\", model_results['recall_macro'])\n            print(\"Recall (Weighted):\", model_results['recall_weighted'])\n            print(\"Precision (Micro):\", model_results['precision_micro'])\n            print(\"Precision (Macro):\", model_results['precision_macro'])\n            print(\"Precision (Weighted):\", model_results['precision_weighted'])\n            print(\"Confusion Matrix:\\n\", model_results['confusion_matrix'])\n            print()\n\n        # Update the best model if necessary\n        if f1_avg > best_f1_score:\n            best_model = (model, use_stemming)\n            best_f1_score = f1_avg\n\n    return best_model\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus1=[]\ndef preprocess_text(text, use_stemming=True, use_lemmatization=True):\n    if use_stemming:\n        stemmer = PorterStemmer()\n        for i in range(len(text)):\n            ## First remove the non word characters\n            review=re.sub('[^a-zA-Z]', ' ' , text[i]) \n            ## To lowcase all the words , so that model learns ,different cases of 1 Alphabet is same letter\n            review=review.lower()\n            ## Split the words\n            review=review.split()\n            ## Then We Exclude the stopwords and stem the words using PorterStemmer stemmer \n            review=[stemmer.stem(word) for word in review if not word in stopwords.words(\"english\")]\n            ## Join all the words \n            review=\" \".join(review)\n            ## append it the Main Corpus list\n            corpus1.append(review)\n    \n    elif use_lemmatization :\n        wnl=WordNetLemmatizer()\n        for i in range(len(text)):\n            review=re.sub('[^a-zA-Z]',\" \", text[i])\n            review=review.lower().split()\n            review=[wnl.lemmatize(word) for word in review if not word in stopwords.words('english')]\n            review=\" \".join(review)\n            corpus1.append(review)\n            \n    return corpus1","metadata":{"execution":{"iopub.status.busy":"2023-06-20T17:51:01.465535Z","iopub.execute_input":"2023-06-20T17:51:01.465897Z","iopub.status.idle":"2023-06-20T17:51:01.476517Z","shell.execute_reply.started":"2023-06-20T17:51:01.465868Z","shell.execute_reply":"2023-06-20T17:51:01.475459Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"text=df['message']\n## Stemmed text after Stemming \nStemmed_text = preprocess_text(text, use_stemming=True, use_lemmatization=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T17:48:31.737691Z","iopub.execute_input":"2023-06-20T17:48:31.738073Z","iopub.status.idle":"2023-06-20T17:48:44.217964Z","shell.execute_reply.started":"2023-06-20T17:48:31.738042Z","shell.execute_reply":"2023-06-20T17:48:44.217056Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"Stemmed_text[2500]","metadata":{"execution":{"iopub.status.busy":"2023-06-20T17:53:08.151562Z","iopub.execute_input":"2023-06-20T17:53:08.151911Z","iopub.status.idle":"2023-06-20T17:53:08.158076Z","shell.execute_reply.started":"2023-06-20T17:53:08.151884Z","shell.execute_reply":"2023-06-20T17:53:08.157057Z"},"trusted":true},"execution_count":117,"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"'rememb ask alex pizza'"},"metadata":{}}]},{"cell_type":"code","source":"text=df['message']\n## Stemmed text after Lemmatization\nLemmatized_text = preprocess_text(text, use_stemming=False, use_lemmatization=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T17:51:09.121269Z","iopub.execute_input":"2023-06-20T17:51:09.121625Z","iopub.status.idle":"2023-06-20T17:51:20.151693Z","shell.execute_reply.started":"2023-06-20T17:51:09.121597Z","shell.execute_reply":"2023-06-20T17:51:20.150542Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"Lemmatized_text[2500]","metadata":{"execution":{"iopub.status.busy":"2023-06-20T17:53:13.108164Z","iopub.execute_input":"2023-06-20T17:53:13.108518Z","iopub.status.idle":"2023-06-20T17:53:13.114578Z","shell.execute_reply.started":"2023-06-20T17:53:13.108491Z","shell.execute_reply":"2023-06-20T17:53:13.113694Z"},"trusted":true},"execution_count":118,"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"'remember ask alex pizza'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Code to preprocess the text based on the use_stemming parameter\n    # You can replace this with your own text preprocessing logic\n    if use_lemmatization:\n        lemmatizer = WordNetLemmatizer()\n        processed_text = [lemmatizer.lemmatize(word) for word in text.split()]\n    else:\n        processed_text = text.split()\n","metadata":{},"execution_count":null,"outputs":[]}]}